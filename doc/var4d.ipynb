{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inversion howto\n",
    "\n",
    "This is an interactive and slightly simplified version of the `var4d.py` script, used for computing the inversions of the GMDD manuscript. It can be used as a tutorial, but is by no means a comprehensive user manual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-11T18:18:15.031194Z",
     "iopub.status.busy": "2020-09-11T18:18:15.030340Z",
     "iopub.status.idle": "2020-09-11T18:18:16.566149Z",
     "shell.execute_reply": "2020-09-11T18:18:16.565516Z",
     "shell.execute_reply.started": "2020-09-11T18:18:15.031110Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import lumia\n",
    "from lumia.obsdb.footprintdb import obsdb\n",
    "from lumia.formatters import lagrange\n",
    "from lumia.interfaces import Interface\n",
    "from lumia.control import monthlyFlux\n",
    "from lumia.Uncertainties import PercentMonthlyPrior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run parameters (rc-file)\n",
    "\n",
    "The settings are stored in a \"rc-file\" (see specific [documentation](rcfiles.html)). Here we use the \"SRefG.rc\" file as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-11T18:18:16.615642Z",
     "iopub.status.busy": "2020-09-11T18:18:16.615367Z",
     "iopub.status.idle": "2020-09-11T18:18:16.620573Z",
     "shell.execute_reply": "2020-09-11T18:18:16.619967Z",
     "shell.execute_reply.started": "2020-09-11T18:18:16.615615Z"
    }
   },
   "outputs": [],
   "source": [
    "rcf = lumia.rc(\"../GMDD/rc/SRefG.rc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the observations database\n",
    "\n",
    "The observation database is pre-processed and stored in a specific format, described [here](obsdb.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-26T12:34:01.525393Z",
     "iopub.status.busy": "2020-08-26T12:34:01.522857Z",
     "iopub.status.idle": "2020-08-26T12:34:02.291217Z",
     "shell.execute_reply": "2020-08-26T12:34:02.290710Z",
     "shell.execute_reply.started": "2020-08-26T12:34:01.525231Z"
    }
   },
   "outputs": [],
   "source": [
    "obsfile = rcf.get('observations.filename')\n",
    "start = datetime(*rcf.get('time.start'))\n",
    "end = datetime(*rcf.get('time.end'))\n",
    "\n",
    "db = obsdb(filename=obsfile, start=start, end=end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the footprint files:\n",
    "\n",
    "The observations dataframe (`db.observations`) should contain a `footprint` column, pointing to the name of the file containing the footprint corresponding to each observation. If not, we use the `obsdb.setupFootprint` method to find the files. The `path` argument points to the location of the files, and the `cache` points to an optional temporary cache where the files might also be (first it looks in the `cache`, then in `path`, and if found in `path` but not in `cache`, it will copy the file to `cache`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking footprints: 100%|██████████| 272/272 [00:05<00:00, 45.85it/s]\n"
     ]
    }
   ],
   "source": [
    "db.setupFootprints(path=rcf.get('footprints.path'), cache=rcf.get('footprints.cache'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refinement of the obs selection:\n",
    "\n",
    "The obs database can be reduced at this stage, for instance by excluding specific sites:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If a \"observations.use_sites\" is defined in the rc-file, then use only these sites (see in \"RA.rc\" for an example)\n",
    "if rcf.get(\"observations.use_sites\", default=False):\n",
    "    db.SelectSites(rcf.get(\"observations.use_sites\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the fluxes\n",
    "\n",
    "We use the `lagrange` observation operator, therefore we use the `lagrange` formatter, from the `lumia.formatters` module, to handle the fluxes in the model space. With this formatter, the fluxes are to be provided in a pre-processed netCDF file, with the file names following the pattern `path/prefix.source.YYYYMM.nc` (see [here](fluxes.html) for full format specifications):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fossil', 'ocean', 'fires', 'biosphere']\n",
      "[]\n",
      "{'fossil': None, 'ocean': None, 'fires': None, 'biosphere': None}\n",
      "EDGAR_eurocom\n",
      "/media/guillaume/EXT4TB/LUMIA/fluxes/nc/eurocom05x05/3h/flux_co2.\n"
     ]
    }
   ],
   "source": [
    "# Read the \"emissions.categories\" and \"emissions.categories.extras\" rc-keys (which should be two lists), and build an empty dictionary with them:\n",
    "categories = dict.fromkeys(rcf.get('emissions.categories') + rcf.get('emissions.categories.extras', default=[]))\n",
    "print(rcf.get('emissions.categories'))\n",
    "print(rcf.get('emissions.categories.extras', default=[]))\n",
    "print(categories)\n",
    "# The pre-processed files are \n",
    "print(rcf.get(f\"emissions.fossil.origin\"))\n",
    "print(rcf.get(\"emissions.prefix\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The pre-processed files are then imported using the `lagrange.ReadArchive` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Importing data for category fossil:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Importing data for category fossil:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[AEmissions from category fossil will be read from file /media/guillaume/EXT4TB/LUMIA/fluxes/nc/eurocom05x05/3h/flux_co2.EDGAR_eurocom.2011.nc\n",
      "\n",
      " 25%|██▌       | 1/4 [00:02<00:08,  2.93s/it]\n",
      "Importing data for category ocean:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:02<00:08,  2.93s/it]\n",
      "Importing data for category ocean:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[AEmissions from category ocean will be read from file /media/guillaume/EXT4TB/LUMIA/fluxes/nc/eurocom05x05/3h/flux_co2.CARBOSCOPEv1_5.2011.nc\n",
      "\n",
      " 50%|█████     | 2/4 [00:04<00:05,  2.66s/it]\n",
      "Importing data for category fires:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 2/4 [00:04<00:05,  2.66s/it]\n",
      "Importing data for category fires:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[AEmissions from category fires will be read from file /media/guillaume/EXT4TB/LUMIA/fluxes/nc/eurocom05x05/3h/flux_co2.GFED_monthly.2011.nc\n",
      "\n",
      " 75%|███████▌  | 3/4 [00:06<00:02,  2.42s/it]\n",
      "Importing data for category biosphere:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:06<00:02,  2.42s/it]\n",
      "Importing data for category biosphere:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[AEmissions from category biosphere will be read from file /media/guillaume/EXT4TB/LUMIA/fluxes/nc/eurocom05x05/3h/flux_co2.ORCHIDEE.2011.nc\n",
      "\n",
      "100%|██████████| 4/4 [00:08<00:00,  2.33s/it]"
     ]
    }
   ],
   "source": [
    "for cat in categories :\n",
    "    categories[cat] = rcf.get(f'emissions.{cat}.origin')\n",
    "emis = lagrange.ReadArchive(rcf.get('emissions.prefix'), start, end, categories=categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the observation operator:\n",
    "\n",
    "The observation operator (`lumia.obsoperator.transport` class) essentially controls the subprocess which runs the actual forward and adjoint transport model (i.e. it launches it, and waits for the results). It also reads and writes the transport model files, but the code for doing that is included in the \"formatter\", which therefore needs to be passed on to the `model` object when instanciating it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lumia.transport(rcf, obs=db, formatter=lagrange)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the control vector \n",
    "\n",
    "An instance from a class from the `lumia.control` module is used to store the various inversion control vectors (prior, posterior and intermediate (pre-conditioned)), the control vector metadata (coordinates, flux category, land mask, etc.), and the prior uncertainties ($\\mathbf{B}$ matrix, decomposed in variances, temporal covariances and spatial covariances). Here we use the `monthlyFlux.Control` class, which defines a monthly flux optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl = monthlyFlux.Control(rcf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of the `Interface`\n",
    "\n",
    "The `Interface`, formally part of the observation operator (and of its adjoint), handles the conversion of data between the control vector (i.e. used by the inversion, typically containing only the optimized fluxes, at the resolution of the inversion, here monthly, 0.5°), and the model structure (which contains also the non-optimized fluxes, such as fossil fuel here, and at the resolution used by the transport model, here 0.5°, 3-hourly).\n",
    "\n",
    "The `Interface` is therefore specific to the couple control vector + transport model, although the correct interface is automatically selected, based on the `name` attributes of the control and model objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "interface = Interface(ctrl.name, model.name, rcf, ancilliary=emis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup prior control vector and uncertainties\n",
    "\n",
    "At this stage, we have the fluxes (in `emis`), we can then construct the prior control vector (i.e. the sum of the monthly biosphere flux). The conversion from fluxes to control vector is handled by the interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "apri = interface.StructToVec(emis)\n",
    "ctrl.setupPrior(apri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prior uncertainty vector can also be set at this stage, using the `ctrl.setupUncertainties` method. However, we need to defined that vector first. For this example, we do it using the `lumia.uncertainties.PercentMonthlyPrior` class, which defines the uncertainty of each control variable as a fraction of the absolute value of that control variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function that is going to compute the uncertainties, as a function of the fluxes:\n",
    "errfunc = PercentMonthlyPrior(rcf, interface)\n",
    "\n",
    "# Call that function, with the fluxes in use, to generate an uncertainty vector\n",
    "err = errfunc(emis)\n",
    "\n",
    "# Set that uncertainty vector as the diagonal of B\n",
    "ctrl.setupUncertainties(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the optimizer and run the inversion\n",
    "\n",
    "We use the conjugate gradient optimizer, defined by the `lumia.optimizer.Optimizer` class. It takes as input variables a rc object (`rcf`), the control vector (`ctrl`), an observation operator (`model`) and the interface between the latter two (`interface`).\n",
    "\n",
    "The inversion is initialized using the `Var4D` method of the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = lumia.optimizer.Optimizer(rcf, ctrl, model, interface)\n",
    "opt.Var4D()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
