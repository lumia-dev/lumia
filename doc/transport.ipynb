{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-11T17:53:49.898337Z",
     "iopub.status.busy": "2020-09-11T17:53:49.897967Z",
     "iopub.status.idle": "2020-09-11T17:53:49.902625Z",
     "shell.execute_reply": "2020-09-11T17:53:49.901848Z",
     "shell.execute_reply.started": "2020-09-11T17:53:49.898302Z"
    }
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "def runprint(cmd):\n",
    "    print(subprocess.check_output(cmd.split()).decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transport model (`lumia.obsoperator` modules and *scripts/lagrange_mp.py* script)\n",
    "\n",
    "The role of the observation operator in the inversion is to compute the observed values ($y$) corresponding to a given control vector $\\mathbf{x}$ (i.e. the vector of variables adjustable by the inversion algorithm). In our case, the observations are a set of atmospheric CO$_2$ concentrations, and the control vector is composed of surface CO$_2$ fluxes, at a variable spatial and temporal resolution, and covering only the *biosphere* (NEE) flux category. The observation operator performs the following tasks:\n",
    "1. Generate a set of high resolution CO$_2$ fluxes, based on the control vector;\n",
    "2. Add to it the fluxes from non-optimized categories (fossil, oceans);\n",
    "3. Compute the impact of these fluxes on CO$_2$ concentrations;\n",
    "4. Add to it the impact of fluxes outside the regional domain (i.e. background fluxes).\n",
    "\n",
    "In adjoint mode, the steps are inverted:\n",
    "1. Compute an adjoint flux field based on a set of model-data mismatches;\n",
    "2. Compute an adjoint control vector based on this adjoint flux field.\n",
    "\n",
    "Technically, step 3 and 4 (and 1 of the adjoint) are performed by a transport model (*lagrange_mp.py* script), which is launched as a subprocess by lumia. \n",
    "This README focuses on these two steps. The construction of transport model inputs from the control vector is described in the *README_interfaces.ipynb* notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our transport model relies on pre-computed observation footprints (i.e. arrays storing the sensitivity of observations to individual flux components):\n",
    "\n",
    "$y^o_{m} = y^o_{bg} + \\sum_c\\left(\\sum_j K^o_{i,j,t} f^c_j\\right)$\n",
    "\n",
    "with $y^o_m$ the model estimate for a given observation $o$; $y^o_{bg}$ is the (prescribed) background concentration (i.e. transport to the observation site of concentrations from the edge of the domain); $K^o$ is the footprint of the observation $o$; $f^c_{i,j,t}$ is the flux estimate for the category $c$ at the coordinates ($i, j, t$).\n",
    "- the footprints $K$ are pre-computed (using a Lagrangian transport model such as FLEXPART or STILT);\n",
    "- the background concentrations are also pre-computed (using a global atmospheric transport model such as TM5);\n",
    "- the fluxes are generated by lumia.\n",
    "\n",
    "In adjoint mode, the model performs the following calculation:\n",
    "\n",
    "$f_{c,i,j,t}^{adj} = \\sum_o K^o_{i,j,t} dy^o$\n",
    "\n",
    "with $dy^o$ the model mismatch computed for the observation $o$ in the preceding forward run.\n",
    "\n",
    "The actual calculations are performed by the *lagrange_mp.py* script, the `lumia.obsoperator` module is in charge of preparing the input files for it, of executing it as a subprocess and of reading in the results. The *lagrange_mp.py* script can therefore be called independently of lumia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-11T17:57:10.335496Z",
     "iopub.status.busy": "2020-09-11T17:57:10.335152Z",
     "iopub.status.idle": "2020-09-11T17:57:12.275935Z",
     "shell.execute_reply": "2020-09-11T17:57:12.275029Z",
     "shell.execute_reply.started": "2020-09-11T17:57:10.335465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: lagrange_mp.py [-h] [--forward] [--adjoint] [--serial]\n",
      "                      [--checkfile CHECKFILE] [--rc RC] --db DB --emis EMIS\n",
      "                      [--verbosity VERBOSITY]\n",
      "                      ...\n",
      "\n",
      "positional arguments:\n",
      "  args\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --forward, -f         Do a forward run\n",
      "  --adjoint, -a         Do an adjoint run\n",
      "  --serial, -s          Run on a single CPU\n",
      "  --checkfile CHECKFILE, -c CHECKFILE\n",
      "  --rc RC\n",
      "  --db DB\n",
      "  --emis EMIS\n",
      "  --verbosity VERBOSITY, -v VERBOSITY\n",
      "\n"
     ]
    }
   ],
   "source": [
    "runprint('../transport/lagrange_mp.py --help')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `--rc`, `--emis` and `--db` arguments define the path of the input files. The `--serial` argument determines whether the run needs to be parallelized or not. The optional `--verbosity` can be set to `DEBUG` for more messages. The optional `--checkfile` points to a (non-existing) empty file that can be written at the end of the forward run, to ensure that it finished correctly.\n",
    "â€‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations/departures file (`--db` argument)\n",
    "\n",
    "The observations are provided as a tar archive of a `lumia.obsdb` database (see *README_obsdb.py*). The \"observations\" table must contain the following columns:\n",
    "- **time**: the time of the observations\n",
    "- **footprint**: the path to the file storing the footprint corresponding to each observation (see below)\n",
    "- **background** (in forward runs only): the background concentration for each obs.\n",
    "- **dy** (in adjoint runs only): the model-data mismatches computed in the forward step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flux file (`--emis` argument)\n",
    "\n",
    "The fluxes are to be provided as a single netCDF file, with one group for each flux category. Below is the (partial) ncdump header of a flux file:\n",
    "```\n",
    "dimensions:\n",
    "\ttime_components = 6 ;\n",
    "\tnt = 2920 ;\n",
    "\tnlat = 80 ;\n",
    "\tnlon = 100 ;\n",
    "\n",
    "group: fossil {\n",
    "  variables:\n",
    "  \tdouble emis(nt, nlat, nlon) ;\n",
    "  \t\temis:units = \"micromol/m2/s\" ;\n",
    "  \tdouble area_m2(nlat, nlon) ;\n",
    "  \tint times_start(nt, time_components) ;\n",
    "  \tint times_end(nt, time_components) ;\n",
    "  \tfloat lats(nlat) ;\n",
    "  \tfloat lons(nlon) ;\n",
    "  } // group fossil\n",
    "\n",
    "group: ocean {\n",
    "  variables:\n",
    "  \tdouble emis(nt, nlat, nlon) ;\n",
    "  \t\temis:units = \"micromol/m2/s\" ;\n",
    "  \tdouble area_m2(nlat, nlon) ;\n",
    "  \tint times_start(nt, time_components) ;\n",
    "  \tint times_end(nt, time_components) ;\n",
    "  \tfloat lats(nlat) ;\n",
    "  \tfloat lons(nlon) ;\n",
    "  } // group ocean\n",
    "```\n",
    "The flux file has two categories: *fossil* and *ocean*. For each flux category, there are 5 mandatory variables:\n",
    "- emis: the surface flux itself (in $\\mu$mol/m$^2$/s);\n",
    "- lats/lons: the coordinates of the center of the grid points;\n",
    "- times_start/times_end: the start and end of each time interval.\n",
    "\n",
    "In adjoint mode, the `--emis` argument specifies the name where the adjoint fluxes are written (in the exact same format)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Footprint files\n",
    "\n",
    "The footprints are stored in HDF5 files. Each file can contain multiple footprints. The footprint file **scripts/example_data/nor.100m.2017-01.h5** is provided as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-11T17:57:17.639803Z",
     "iopub.status.busy": "2020-09-11T17:57:17.639342Z",
     "iopub.status.idle": "2020-09-11T17:57:17.695179Z",
     "shell.execute_reply": "2020-09-11T17:57:17.693970Z",
     "shell.execute_reply.started": "2020-09-11T17:57:17.639750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDF5 \"footprints/nor.100m.2017-01.h5\" {\n",
      "DATASET \"latitudes\" {\n",
      "   DATATYPE  H5T_IEEE_F64LE\n",
      "   DATASPACE  SIMPLE { ( 32 ) / ( 32 ) }\n",
      "   DATA {\n",
      "   (0): 54.25, 54.75, 55.25, 55.75, 56.25, 56.75, 57.25, 57.75, 58.25, 58.75,\n",
      "   (10): 59.25, 59.75, 60.25, 60.75, 61.25, 61.75, 62.25, 62.75, 63.25,\n",
      "   (19): 63.75, 64.25, 64.75, 65.25, 65.75, 66.25, 66.75, 67.25, 67.75,\n",
      "   (28): 68.25, 68.75, 69.25, 69.75\n",
      "   }\n",
      "}\n",
      "DATASET \"longitudes\" {\n",
      "   DATATYPE  H5T_IEEE_F64LE\n",
      "   DATASPACE  SIMPLE { ( 60 ) / ( 60 ) }\n",
      "   DATA {\n",
      "   (0): 0.25, 0.75, 1.25, 1.75, 2.25, 2.75, 3.25, 3.75, 4.25, 4.75, 5.25,\n",
      "   (11): 5.75, 6.25, 6.75, 7.25, 7.75, 8.25, 8.75, 9.25, 9.75, 10.25, 10.75,\n",
      "   (22): 11.25, 11.75, 12.25, 12.75, 13.25, 13.75, 14.25, 14.75, 15.25,\n",
      "   (31): 15.75, 16.25, 16.75, 17.25, 17.75, 18.25, 18.75, 19.25, 19.75,\n",
      "   (40): 20.25, 20.75, 21.25, 21.75, 22.25, 22.75, 23.25, 23.75, 24.25,\n",
      "   (49): 24.75, 25.25, 25.75, 26.25, 26.75, 27.25, 27.75, 28.25, 28.75,\n",
      "   (58): 29.25, 29.75\n",
      "   }\n",
      "}\n",
      "GROUP \"20170131140000/20170131150000_20170131120000\" {\n",
      "   DATASET \"ilats\" {\n",
      "      DATATYPE  H5T_STD_I32LE\n",
      "      DATASPACE  SIMPLE { ( 4 ) / ( 4 ) }\n",
      "      DATA {\n",
      "      (0): 11, 12, 11, 12\n",
      "      }\n",
      "   }\n",
      "   DATASET \"ilons\" {\n",
      "      DATATYPE  H5T_STD_I32LE\n",
      "      DATASPACE  SIMPLE { ( 4 ) / ( 4 ) }\n",
      "      DATA {\n",
      "      (0): 33, 33, 34, 34\n",
      "      }\n",
      "   }\n",
      "   DATASET \"resp\" {\n",
      "      DATATYPE  H5T_IEEE_F32LE\n",
      "      DATASPACE  SIMPLE { ( 4 ) / ( 4 ) }\n",
      "      DATA {\n",
      "      (0): 0.000382113, 0.000101582, 0.140966, 1.1165\n",
      "      }\n",
      "   }\n",
      "}\n",
      "GROUP \"20170131140000/20170131120000_20170131090000\" {\n",
      "   DATASET \"ilats\" {\n",
      "      DATATYPE  H5T_STD_I32LE\n",
      "      DATASPACE  SIMPLE { ( 6 ) / ( 6 ) }\n",
      "      DATA {\n",
      "      (0): 11, 12, 11, 12, 11, 12\n",
      "      }\n",
      "   }\n",
      "   DATASET \"ilons\" {\n",
      "      DATATYPE  H5T_STD_I32LE\n",
      "      DATASPACE  SIMPLE { ( 6 ) / ( 6 ) }\n",
      "      DATA {\n",
      "      (0): 32, 32, 33, 33, 34, 34\n",
      "      }\n",
      "   }\n",
      "   DATASET \"resp\" {\n",
      "      DATATYPE  H5T_IEEE_F32LE\n",
      "      DATASPACE  SIMPLE { ( 6 ) / ( 6 ) }\n",
      "      DATA {\n",
      "      (0): 0.000332498, 8.70813e-05, 0.733297, 0.232641, 0.405773, 0.345584\n",
      "      }\n",
      "   }\n",
      "}\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The file contains many footprints, we just show a fraction of it..\n",
    "runprint('h5dump -d latitudes -d longitudes -g 20170131140000/20170131150000_20170131120000 -g 20170131140000/20170131120000_20170131090000 footprints/nor.100m.2017-01.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file has a hierachical structure:\n",
    "- The higher level contains two datasets (`latitudes` and `longitudes`, showing the coordinates of the center of the grid points), and many groups, each containing the footprint of one observation (i.e. $K^i$). In the example above, an extract of the group `20170131140000` are displayed. The observations are identified by their time (here 2017/01/31 14:00), which means that there cannot be two observations at the same time in the same file (typically, using different footprint files for different observation sites avoids problems).\n",
    "- Each footprint group contains itself several (many) subgroups. Each contains the information needed to reconstruct a slice of the footprint along its time axis (i.e. $K^i_t$). The group name corresponds to the time interval (which itself must match the time intervals of the emissions!). For instance the group `20170131140000/20170131120000_20170131090000` contains the sensitivity of the observation `20170131140000` to surface fluxes on 2017/01/13 from 9:00 to 12:00.\n",
    "    - the `resp` datasets contain the non-zero values of $K$\n",
    "    - the `ilats` and `ilons` datasets contain the latitude and longitude of the values in the `resp` datasets.\n",
    "    \n",
    "The script below shows how to reconstruct the 3D footprints from the example file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-11T17:57:21.971015Z",
     "iopub.status.busy": "2020-09-11T17:57:21.970692Z",
     "iopub.status.idle": "2020-09-11T17:57:23.028382Z",
     "shell.execute_reply": "2020-09-11T17:57:23.027117Z",
     "shell.execute_reply.started": "2020-09-11T17:57:21.970981Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file has footprints for the following observations times:\n",
      "2017-01-31 11:00:00\n",
      "2017-01-31 12:00:00\n",
      "2017-01-31 13:00:00\n",
      "2017-01-31 14:00:00\n"
     ]
    }
   ],
   "source": [
    "from h5py import File\n",
    "from datetime import datetime\n",
    "from numpy import zeros, array\n",
    "footprints = {}\n",
    "with File('footprints/nor.100m.2017-01.h5', 'r') as fp:\n",
    "    lons = fp['longitudes'][:]\n",
    "    lats = fp['latitudes'][:]\n",
    "    nlon, nlat = len(lons), len(lats)\n",
    "    \n",
    "    # Loop over all the footprints in the file\n",
    "    print(\"The file has footprints for the following observations times:\")\n",
    "    for obs in fp.keys():\n",
    "        if obs not in ['latitudes', 'longitudes']:\n",
    "            date = datetime.strptime(obs, '%Y%m%d%H%M%S')\n",
    "            print(date)\n",
    "            ts, te, fpt = [], [], []\n",
    "            \n",
    "            # Loop over all the time steps of the current footprint\n",
    "            for tstep in sorted(fp[obs]):\n",
    "                t1, t0 = tstep.split('_')\n",
    "                ts.append(datetime.strptime(t0, '%Y%m%d%H%M%S'))\n",
    "                te.append(datetime.strptime(t1, '%Y%m%d%H%M%S'))\n",
    "                data = zeros((nlat, nlon))\n",
    "                ilons = fp[obs][tstep]['ilons'][:]\n",
    "                ilats = fp[obs][tstep]['ilats'][:]\n",
    "                data[ilats, ilons] = fp[obs][tstep]['resp'][:]\n",
    "                fpt.append(data)\n",
    "                \n",
    "            # Each element of the \"footprints\" dictionary contains a sub-dictionary, with one \"value\" variable (the 3D footprint), and four coordinate variables\n",
    "            footprints[date] = {'start':array(ts), 'end':array(te), 'value':array(fpt), 'lons':lons, 'lats':lats}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rc-file (`--rc` argument)\n",
    "\n",
    "In forward runs, the rc file requires the two following keys:\n",
    "- `model.transport.split`: determines on how many CPUs the computations are parallelized (see parallelisation section below)\n",
    "- `path.run`: determines where the model output is written\n",
    "\n",
    "In adjoint runs, the following keys are also required, to construct the adjoint flux file. These are given here for reference but are normally automatically generated by lumia.\n",
    "- `emissions.categories`: the names of the flux categories transported\n",
    "- for each category `cat`, an `emissions.cat.optimize` key (with a boolean value)\n",
    "- for each category `cat`, an `emissions.cat.interval` key, setting the time interval at which the fluxes are defined\n",
    "- `time.start` and `time.end`: start and end times of the inversion (in a \"yyyy, mm, dd, [HH, mm]\" format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelisation\n",
    "\n",
    "The transport model is parallelised by splitting the observation database in chunks of approximately equal size. Several subprocesses are then launched (one for each chunk of the database). This is handled directly by *lagrange_mp.py* script: it splits the database and lauches subprocesses of itself with the `--serial` argument (which specifies that no further splitting should occur).\n",
    "\n",
    "This parallelization is very efficient as each process reads different footprint files (and the I/O is the limitation here). It has two practical consequences:\n",
    "- no additional library is required, it can run on any system\n",
    "- multi-nodes systems are not handled: the number of processes is limited by the number of CPUs on the machine"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
